{"pageProps":{"currentPost":{"slug":"kubernetes-cluster","frontMatter":{"title":"How to Set Up a Kubernetes Cluster on Linux Using MicroK8s or K3s","description":"Kubernetes is an essential tool in the modern tech stack, and the ability to run it efficiently on Linux—whether for development or production—is crucial for developers and DevOps engineers.","image":"/images/blog/kubernetes.jpg","date":"2024-12-28","category":"Server"},"content":"\nIn this article, we'll cover how to set up a Kubernetes cluster using two popular solutions: MicroK8s and K3s.\n\nWe’ll cover:\n\n1. What MicroK8s and K3s are.\n2. How to install each solution on a Linux system.\n3. Setting up a functional cluster, either on a single machine or multiple nodes.\n4. Testing the cluster with a practical example.\n\n\n## What Are MicroK8s and K3s?\n\nMicroK8s:\n\nMicroK8s is a lightweight Kubernetes distribution developed by Canonical (the team behind Ubuntu). It’s designed to be:\n\n1. Easy to install and configure, especially for Ubuntu users.\n2. Ideal for local development or single-node setups.\n3. Simple to expand by enabling preconfigured modules like DNS, the Kubernetes dashboard, or storage support.\n\n<em>Use Cases</em>:\n   - Local Kubernetes Development: Ideal for testing applications and scripts in a local Kubernetes environment.\n   - CI/CD Pipelines: Its fast setup makes it great for continuous integration and delivery workflows.\n   - Edge Computing: Small resource requirements make it well-suited for deploying Kubernetes on IoT or edge devices.\n   - Educational Purposes: Simplified Kubernetes environment for learning and experimentation.\n\nK3s:\n\nK3s, developed by Rancher Labs, is a lightweight version of Kubernetes that:\n\n1. Is designed for resource-constrained devices like Raspberry Pi or edge servers.\n2. Reduces complexity by removing less commonly used components.\n3. Works great for distributed clusters with multiple nodes, using a one-liner installation.\n\n<em>Use Cases</em>:\n   - Edge and IoT Devices: K3s is designed to work well in environments where computing power, memory, or storage is limited, such as edge devices or IoT gateways.\n   - Small Clusters: It's perfect for small Kubernetes clusters or development environments that need to be fast and lightweight.\n   - CI/CD Pipelines: Developers can use K3s to set up local Kubernetes clusters for testing or continuous integration purposes without the overhead of a full Kubernetes deployment.\n   - Cloud and Virtualized Environments: You can use K3s for managing Kubernetes clusters in resource-constrained cloud instances or virtualized environments where Kubernetes might otherwise be too heavy.\n\n<strong>Which one should you choose?</strong>\n\n<em>Choose MicroK8s if you’re working on a single system or are in the Ubuntu ecosystem.</em>\n\n<em>Choose K3s if you need a distributed cluster or are working with limited hardware.</em>\n\n\n##  Prerequisites\n\nHardware Requirements:\n\n- Single-node: At least 2 GB of RAM, 2 CPU cores.\n- Multi-node: At least 2 GB of RAM per node with multi-core processors.\n- Disk space: 20 GB per node (SSD recommended).\n\nSoftware Requirements:\n1. Operating System:\n    - Ubuntu 20.04 or later (ideal for MicroK8s).\n    - Other Linux distributions (Debian, CentOS, RHEL) work well with K3s.\n2. Networking tools: Ensure the firewall allows Kubernetes traffic.\n3. Root/sudo access on all nodes in the cluster.\n\n\n## Installing and Configuring MicroK8s\nStep 1: Install MicroK8s\nMicroK8s can be installed easily using Snap. On Ubuntu-based systems:\n\n```bash\nsudo snap install microk8s --classic\n```\n\nStep 2: Configure the User\nAfter installation, you’ll need to add your current user to the microk8s group:\n\n```bash\nsudo usermod -a -G microk8s $USER\nsudo chown -R $USER ~/.kube\n```\nRestart your terminal session to apply the changes.\n\nStep 3: Enable Useful Add-ons\nMicroK8s comes with pre-installed but disabled add-ons. Enable commonly used ones:\n\n```bash\nmicrok8s enable dns dashboard storage\n```\n\nThese will enable internal DNS, the Kubernetes dashboard, and storage.\n\nStep 4: Check Cluster Status\nEnsure everything is set up correctly:\n\n```bash\nmicrok8s status --wait-ready\n```\n\n\n## Installing and Configuring K3s\nStep 1: Install the Master Node\nOn the main (master) node, run the following command to install K3s:\n\n```bash\ncurl -sfL https://get.k3s.io | sh -\n```\n\nThis will download and automatically configure K3s. A kubeconfig file will be generated and can be found at /etc/rancher/k3s/k3s.yaml.\n\nStep 2: Get the Token\nTo add worker nodes, you’ll need the token generated during installation. Retrieve it with:\n\n```bash\ncat /var/lib/rancher/k3s/server/node-token\n```\n\nStep 3: Add Worker Nodes\nOn each worker node, install K3s and connect it to the master:\n```bash\ncurl -sfL https://get.k3s.io | K3S_URL=https://<MASTER_IP>:6443 K3S_TOKEN=<TOKEN> sh -\n```\n\nStep 4: Verify the Cluster\nOn the master node, verify the connected nodes:\n\n```bash\nkubectl get nodes\n```\n\n## Testing the Cluster\nTo confirm that your cluster is working correctly, deploy a simple application:\n\n```bash\nkubectl create deployment nginx --image=nginx\nkubectl expose deployment nginx --type=NodePort --port=80\n```\n\nFind the exposed port using:\n\n```bash\nkubectl get services\n```\nAccess the application at http://<NODE_IP>:<PORT>.\n\n## Troubleshooting Common Issues in Kubernetes Clusters\n\nEven with a solid Kubernetes setup, issues are bound to arise. Here are some of the most common problems and how to address them effectively:\n\n1. DNS Issues in MicroK8s\nIf DNS isn’t working:\n  - Check if CoreDNS is running:\n```bash\nmicrok8s kubectl get pods -n kube-system\n```  \n\n  - If it's in CrashLoopBackOff, check the logs:\n```bash \nmicrok8s kubectl logs -n kube-system <coredns-pod-name>  \n```\n\n  - Ensure that iptables isn’t blocking DNS traffic:\n```bash\nsudo iptables -F  \n```\n\n2. Worker Nodes Not Connecting in K3s\nIf a worker node isn’t showing up in kubectl get nodes:\n\n   - Verify that you’re using the correct URL and token from the master node:\n```bash\ncat /var/lib/rancher/k3s/server/node-token  \n```\n\nOpen port 6443 on the master node:\n```bash\nsudo ufw allow 6443/tcp\n```\n3. Service Inaccessible\nIf your applications are unreachable:\n\n  - Check the NodePort for your service:\n```bash\nkubectl get services\n```\n  - Ensure readiness probes are properly configured:\n```bash\nkubectl describe pod <pod-name>  \n```\n\n  - Open the NodePort range (30000-32767):\n```bash\nsudo ufw allow 30000:32767/tcp  \n```\n\n4. Cluster Nodes in ‘NotReady’ State\nIf nodes are marked as NotReady:\n\n   - Check hardware resources:\n```bash\nfree -h\n```\n\n  - Make sure the container runtime (e.g., Docker/Containerd) is running:\n```bash\nsudo systemctl restart docker\n```\n\n   - Reinstall networking plugins:\n```bash\nmicrok8s enable dns flannel  \n```\n\n5. Pods Stuck in Pending State\nWhen pods can’t be scheduled:\n\n   - Inspect events for the pod:\n```bash\nkubectl describe pod <pod-name>  \n```\n\n   - Remove unnecessary taints from nodes:\n```bash\nkubectl taint nodes <node-name> key=value:NoSchedule-  \n```\n\nThese tips will help you quickly diagnose and resolve most Kubernetes cluster issues. The key is to dive into logs and system events to pinpoint where things are breaking down. Good luck! "},"previousPost":{"slug":"jenkins-and-https","frontMatter":{"title":"Guide to Setting Up a Django Server with Nginx and Gunicorn","description":"This step-by-step guide will show you how to set up a web server for your Django app using Nginx and Gunicorn on an Ubuntu server. We'll walk you through everything from installing the necessary packages to configuring your environment to run Django in production. Let's get started!","image":"/images/blog/django.jpg","date":"2025-01-04","category":"Server"},"content":"\n\n## Preparing the Server\n\nFirst things first: we need to update your server and install the essential packages.\n\n -  Run these commands to update and install everything you need:\n\n```bash\nsudo apt update && sudo apt upgrade -y\nsudo apt install python3-pip python3-venv python3-dev libpq-dev nginx -y\n```\n\nHere’s what each package is for:\n\n- `python3-pip`: The tool that lets you install Python packages you’ll need for your app.\n    \n- `python3-venv`: Allows you to create a virtual environment for Python—this keeps things nice and clean.\n    \n- `python3-dev`: Development headers and libraries for building Python packages.\n    \n- `libpq-dev`: Required for connecting your Django app to PostgreSQL if you're using that as your database.\n    \n-  `nginx`: This is the web server we’re going to use to serve your Django app.\n\n----------\n\n### Creating the App Directory\n\nNow let’s create the directory where your Django app will live and set the right permissions.\n\n1.  Make the directory:\n\n```bash\nsudo mkdir -p /var/www/domain.com/app\n```\n2.  Set the correct permissions:\n\n```bash\nsudo chown -R $USER:$USER /var/www/domain.com/app\nsudo chmod -R 755 /var/www/domain.com\n``` \nWhat’s happening here:\n-   `mkdir -p`: Makes sure all the necessary folders are created (even the ones in the path).\n  \n-   `chown`: Changes the ownership of the directory to the current user (you).\n  \n-  `chmod`: Ensures the right read/execute permissions for the directory.\n\n----------\n\n### Configuring Nginx for Your App\n\nNow it’s time to set up Nginx to serve your Django app. Let’s create a configuration file for your domain.\n\n1.  Create the config file:\n```bash\nsudo nano /etc/nginx/sites-available/domain.com\n```\n\n2.  Add the following content to the file:\n\n\n```bash\n`server {\n    listen 80;\n    server_name domain.com www.domain.com;\n\n    root /var/www/domain.com/html;\n    index index.html;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}` \n```\nWhat’s happening here:\n -   `listen 80`: Tells Nginx to listen for HTTP traffic on port 80 (the standard for web traffic).\n    \n -   `server_name`: This specifies which domains Nginx should handle with this config.\n   \n -  `try_files`: It checks if the requested files exist. If not, it returns a 404 error.\n\n----------\n\n### Setting Up SSL with Let's Encrypt\n\nFor added security, you should use HTTPS. If you don’t already have an SSL certificate, Let’s Encrypt is a free, trusted option.\n\n1.  First, let’s redirect all HTTP traffic to HTTPS:\n\n\n```bash\nserver {\n    listen 80;\n    server_name domain.com www.domain.com;\n    return 301 https://$host$request_uri;\n}\n```\n\n2.  Next, let’s set up the HTTPS server configuration:\n\n```bash\nserver {\n    listen 443 ssl;\n    server_name domain.com www.domain.com;\n\n    ssl_certificate /etc/letsencrypt/live/domain.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/domain.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n    location / {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    location /static/ {\n        alias /var/www/domain.com/app/static/;\n    }\n}\n``` \n\n Here’s what’s going on:\n-   `proxy_pass`: This tells Nginx to forward incoming requests to Gunicorn (which will run your Django app on port 8000).\n    \n-   `alias`: This directs Nginx to the static files folder where your Django app will store its static assets.\n\n----------\n\n### Activating the Nginx Configuration and Restarting the Service\n\nNow that we’ve got Nginx set up, let’s activate the configuration and restart Nginx.\n\n1.  Enable the site by creating a symbolic link:\n\n```bash\nsudo ln -s /etc/nginx/sites-available/domain.com /etc/nginx/sites-enabled/` \n```\n\n2.  Check for configuration errors:\n```bash\nsudo nginx -t\n```\n\n3.  If everything checks out, restart Nginx:\n```bash\nsudo systemctl restart nginx\n```\n\n----------\n\n## Setting Up the Django Project\n\nNext, let’s get your Django project set up and ready to go!\n\n1.  Create a virtual environment for Python:\n\n```bash\ncd /var/www/domain.com/app\npython3 -m venv venv\nsource venv/bin/activate \n```\n\n2.  Install Django and Gunicorn:\n\n```bash\npip install django gunicorn \n```\n\n----------\n\n### Creating the Django Project\n\n1.  Now, let’s create a new Django project:\n\n```bash\ndjango-admin startproject myproject .\n```\n\n2.  To test that everything’s running, start the Django development server:\n\n```bash\npython3 manage.py runserver\n```\n\n----------\n\n### Configuring Static Files\n\n1.  Create the static files directory:\n\n```bash\nmkdir -p /var/www/domain.com/app/static\n```\n\n2.  Update `settings.py` to point to the correct location for static files:\n\n\n```bash\nSTATIC_ROOT = \"/var/www/domain.com/app/static/\"\nSTATIC_URL = \"/static/\"\n```\n\n3.  Collect all the static files:\n```bash\npython manage.py collectstatic\n```\n-----------\n#### In Django, handling static files—like CSS, JavaScript, and images—requires special attention because of how static content is served in production versus development. Let’s break it down:\n\nWhy Static Files Need Configuration ?\n\nBy default, Django is optimized for development, and during development, it automatically serves static files using its built-in development server. However, this approach isn't suitable for production due to performance and security concerns. Instead:\n\nIn Development:\n\n   - Django's development server (e.g., when you run python manage.py runserver) handles static files directly, pulling them from the STATICFILES_DIRS or app-specific static folders (<app_name>/static).\nYou don't need to create or configure STATIC_ROOT or manually run collectstatic.\n\nIn Production:\n\n   - A web server like Nginx or Apache should serve static files. This ensures better performance since serving static assets isn’t what Django’s application server (like Gunicorn) is designed for.\nDjango needs all static files from various apps to be gathered into a single directory, specified by STATIC_ROOT. This is why the collectstatic command is necessary.\nWithout a properly set STATIC_ROOT, you can't collect and serve static files efficiently in production.\n\nWhy Create the Directory Manually?\n\n   - The directory defined by STATIC_ROOT (e.g., /var/www/domain.com/app/static/) is where Django collects all static files when you run:\n\n```bash\npython manage.py collectstatic\n```\n\nYou need to create this directory manually because:\n\n1. It's not automatically created by Django: Django only expects the STATIC_ROOT setting to point to an existing location.\n  \n2. Flexibility in deployment: You might want the static directory to be in a specific location, independent of Django’s project structure. For example, /var/www/... is commonly used in production setups.\n   \nDo You Need This in Both Production and Development?\n   - In Production: Yes, always. The STATIC_ROOT directory and the collectstatic process are essential in production environments because Django doesn’t serve static files directly. Instead, the web server (e.g., Nginx) will use the collected files.\n   - In Development: Not typically. Django's development server handles static files automatically using the STATICFILES_DIRS and app-specific static folders. You don't need to configure STATIC_ROOT or run collectstatic.\n\nIf you're testing a production-like environment locally, you might set it up in development to mirror production, but it’s optional.\n\n#### Key Takeaway\n\nThe manual creation of the STATIC_ROOT directory and running collectstatic are production-specific requirements. In development, Django simplifies the process, but in production, separating the app logic from static file serving is critical for performance and scalability.\n\n-----------\n4.  Set the right permissions on the static files folder:\n\n```bash\nsudo chown -R www-data:www-data /var/www/domain.com/app/static\nsudo chmod -R 755 /var/www/domain.com/app/static\n```\n\n\n\n### Setting Up the Gunicorn Service\n\nGunicorn will serve your Django app, so let’s set it up with a systemd service.\n\n1.  Create the Gunicorn service file:\n\n```bash\nsudo nano /etc/systemd/system/gunicorn.service\n```\n\n2.  Add the following configuration:\n\n```bash\n[Unit]\nDescription=gunicorn daemon for Django project\nAfter=network.target\n\n[Service]\nUser=www-data\nGroup=www-data\nWorkingDirectory=/var/www/domain.com/app\nExecStart=/var/www/domain.com/app/venv/bin/gunicorn --workers 3 --bind 127.0.0.1:8000 myproject.wsgi:application\n\n[Install]\nWantedBy=multi-user.target\n```\n\n3.  Check the permissions:\n\n```bash\nls -l /etc/systemd/system/gunicorn.service\n```\n\nIf the permissions need fixing:\n\n```bash\nsudo chmod 644 /etc/systemd/system/gunicorn.service\n```\n\n----------\n\n### Starting the Gunicorn Service\n\n1.  Enable and start Gunicorn:\n\n```bash\nsudo systemctl start gunicorn\nsudo systemctl enable gunicorn\n```\n\n\n2.  To check that everything’s working:\n\n\n```bash\nsudo systemctl status gunicorn\n``` \n\n----------\n\nAnd that’s it! You’ve successfully set up your Django app with Nginx and Gunicorn. Your app is now ready to handle traffic in production, and you’ve ensured it’s secure and performant. Enjoy the smooth sailing!\n"},"nextPost":{"slug":"linux-file-system","frontMatter":{"title":"ZFS vs Btrfs vs EXT4: Which File System Should You Choose in 2025?","description":"When selecting a file system for your projects, it's essential to understand the pros and cons of each option based on the specific context in which you'll be using it. In 2025, ZFS, Btrfs, and EXT4 are three of the most popular choices, each with features that make them suitable for different environments, from desktops and servers to NAS (Network-Attached Storage). In this article, we'll break down each file system, comparing them in terms of characteristics, performance, and compatibility.","image":"/images/blog/ZFSvsBtrfsvsEXT4.jpg","date":"2024-12-29","category":"Server"},"content":"\n\n## EXT4 - Tried-and-True Stability and Simplicity\n\nEXT4 is undoubtedly the most widely used file system in Linux distributions and is often the go-to choice for users looking for stability and compatibility. Developed in 2008 as an improvement over EXT3, EXT4 offers excellent performance and resource efficiency.\n\nAdvantages:\n   - Stability and compatibility: EXT4 is incredibly stable and supported across almost all Linux distributions and management tools.\n   - Fast read/write performance: It performs very well with small to medium-sized files.\n   - Resilience to failure: With journaling, EXT4 ensures data integrity during sudden shutdowns.\n   - Moderate scalability: It can handle volumes up to 1 exabyte and file sizes up to 16 TB.\n\nDisadvantages:\n   - Lack of advanced features: EXT4 doesn't offer advanced features like deduplication, snapshots, or file compression that are available in other file systems.\n   - Not the best for handling very large files: It’s less efficient when working with massive files or complex data sets.\n\n<em>When to choose EXT4?</em>\n\n   - Desktops: If you need a stable and fast file system for a personal PC or laptop, EXT4 is a safe bet.\n   - Servers: For servers that don't require advanced functionality, EXT4 is often enough, but for large data sets or more data protection, other options may be better.\n   - NAS: If you’re using a NAS that doesn’t rely on complex backups and advanced data protection, EXT4 will serve you well.\n\n\n## ZFS - Advanced Data Protection and Performance\n\nOriginally developed by Sun Microsystems and now available on most Linux and BSD systems, ZFS is a file system known for its advanced features. It's frequently used in enterprise environments due to its ability to manage massive volumes of data and offer superior data protection.\n\nAdvantages:\n   - Data protection: ZFS includes mechanisms for checking and correcting errors at the file and disk levels.\n   - Snapshots and cloning: It supports fast snapshots and cloning, making backups and data restoration extremely quick.\n   - Deduplication and compression: ZFS allows for data deduplication to save space and file compression to reduce storage needs.\n   - Massive scalability: ZFS can handle file systems from a few gigabytes to hundreds of terabytes.\n   - Software RAID: It manages RAID directly at the file system level, providing additional protection compared to hardware RAID.\n\nDisadvantages:\n   - High resource usage: ZFS is known for its heavy memory and CPU requirements, making it less suitable for resource-limited systems.\n   - Limited compatibility: While available on Linux and BSD, ZFS isn’t natively supported on all distributions and is not available on Windows or macOS.\n   - Complex administration: Managing ZFS can be more challenging compared to EXT4, requiring more advanced knowledge.\n\n<em>When to choose ZFS?</em>\n\n   - Servers: ZFS is ideal for servers handling large volumes of data that require advanced data protection and fast backup capabilities.\n   - NAS: For NAS systems requiring reliability, quick backups, and data protection, ZFS is a top choice.\n   - Enterprise projects: Any infrastructure dealing with large files, snapshots, and fast recovery will benefit greatly from ZFS.\n\n\n\n## Btrfs - Flexibility and Advanced Features\n\nBtrfs is a younger file system compared to ZFS and EXT4, but it has rapidly gained popularity due to its advanced features, which are similar to ZFS. It was developed as a modern alternative to traditional file systems, optimized for managing large volumes and complex data.\n\nAdvantages:\n   - Snapshots and subvolumes: Btrfs allows for creating snapshots and subvolumes, making backups and data management more efficient.\n   - Compression and deduplication: Btrfs supports file compression and deduplication, saving a lot of storage space.\n   - Good performance with large files: It's faster than EXT4 when handling large files and large amounts of data.\n   - Linux integration: It’s natively supported by most Linux distributions, making it easy to implement on modern systems.\n\nDisadvantages:\n   - Instability in certain situations: While Btrfs is constantly improving, it has had some stability issues in the past, especially in production environments.\n   - Lower performance on older hardware: Using Btrfs on older systems or traditional hard drives may not be as fast or efficient.\n   - Not as robust as ZFS: While Btrfs offers many advanced features, it’s still not as mature or robust as ZFS for managing large-scale data.\n\n<em>When to choose Btrfs?</em>\n\n   - Desktops: Btrfs is a great choice for advanced users looking to experiment with features like deduplication, snapshots, and compression.\n   - Servers and NAS: For environments where managing large volumes of data and data protection are important, Btrfs is a viable option, though you should be mindful of its stability.\n   - Projects requiring a balance of performance and protection: If you need a modern file system with advanced features but don’t require the complexity of ZFS, Btrfs is a solid alternative.\n\n\n## Conclusion: Which File System Should You Choose in 2025?\nEach of these file systems has its own advantages and disadvantages, and the choice depends on your needs and resources.\n\n   - For desktops and users seeking simplicity and stability, EXT4 remains the go-to choice.\n   - For servers and NAS that need advanced data protection and large-scale data management, ZFS is the top pick.\n   - For users who want a balance of advanced features and performance without ZFS’s complexity, Btrfs is a modern and flexible choice.\n\nUltimately, based on your projects and available resources, you’ll be able to choose the file system that best meets your needs.\n"}},"__N_SSG":true}