{"pageProps":{"currentPost":{"slug":"kubernetes-cluster","frontMatter":{"title":"How to Set Up a Kubernetes Cluster on Linux Using MicroK8s or K3s","description":"Kubernetes is an essential tool in the modern tech stack, and the ability to run it efficiently on Linux—whether for development or production—is crucial for developers and DevOps engineers.","image":"/images/blog/kubernetes.jpg","date":"2024-12-28","category":"Server"},"content":"\nIn this article, we'll cover how to set up a Kubernetes cluster using two popular solutions: MicroK8s and K3s.\n\nWe’ll cover:\n\n1. What MicroK8s and K3s are.\n2. How to install each solution on a Linux system.\n3. Setting up a functional cluster, either on a single machine or multiple nodes.\n4. Testing the cluster with a practical example.\n\n\n## What Are MicroK8s and K3s?\n\nMicroK8s:\n\nMicroK8s is a lightweight Kubernetes distribution developed by Canonical (the team behind Ubuntu). It’s designed to be:\n\n1. Easy to install and configure, especially for Ubuntu users.\n2. Ideal for local development or single-node setups.\n3. Simple to expand by enabling preconfigured modules like DNS, the Kubernetes dashboard, or storage support.\n\n<em>Use Cases</em>:\n   - Local Kubernetes Development: Ideal for testing applications and scripts in a local Kubernetes environment.\n   - CI/CD Pipelines: Its fast setup makes it great for continuous integration and delivery workflows.\n   - Edge Computing: Small resource requirements make it well-suited for deploying Kubernetes on IoT or edge devices.\n   - Educational Purposes: Simplified Kubernetes environment for learning and experimentation.\n\nK3s:\n\nK3s, developed by Rancher Labs, is a lightweight version of Kubernetes that:\n\n1. Is designed for resource-constrained devices like Raspberry Pi or edge servers.\n2. Reduces complexity by removing less commonly used components.\n3. Works great for distributed clusters with multiple nodes, using a one-liner installation.\n\n<em>Use Cases</em>:\n   - Edge and IoT Devices: K3s is designed to work well in environments where computing power, memory, or storage is limited, such as edge devices or IoT gateways.\n   - Small Clusters: It's perfect for small Kubernetes clusters or development environments that need to be fast and lightweight.\n   - CI/CD Pipelines: Developers can use K3s to set up local Kubernetes clusters for testing or continuous integration purposes without the overhead of a full Kubernetes deployment.\n   - Cloud and Virtualized Environments: You can use K3s for managing Kubernetes clusters in resource-constrained cloud instances or virtualized environments where Kubernetes might otherwise be too heavy.\n\n<strong>Which one should you choose?</strong>\n\n<em>Choose MicroK8s if you’re working on a single system or are in the Ubuntu ecosystem.</em>\n\n<em>Choose K3s if you need a distributed cluster or are working with limited hardware.</em>\n\n\n##  Prerequisites\n\nHardware Requirements:\n\n- Single-node: At least 2 GB of RAM, 2 CPU cores.\n- Multi-node: At least 2 GB of RAM per node with multi-core processors.\n- Disk space: 20 GB per node (SSD recommended).\n\nSoftware Requirements:\n1. Operating System:\n    - Ubuntu 20.04 or later (ideal for MicroK8s).\n    - Other Linux distributions (Debian, CentOS, RHEL) work well with K3s.\n2. Networking tools: Ensure the firewall allows Kubernetes traffic.\n3. Root/sudo access on all nodes in the cluster.\n\n\n## Installing and Configuring MicroK8s\nStep 1: Install MicroK8s\nMicroK8s can be installed easily using Snap. On Ubuntu-based systems:\n\n```bash\nsudo snap install microk8s --classic\n```\n\nStep 2: Configure the User\nAfter installation, you’ll need to add your current user to the microk8s group:\n\n```bash\nsudo usermod -a -G microk8s $USER\nsudo chown -R $USER ~/.kube\n```\nRestart your terminal session to apply the changes.\n\nStep 3: Enable Useful Add-ons\nMicroK8s comes with pre-installed but disabled add-ons. Enable commonly used ones:\n\n```bash\nmicrok8s enable dns dashboard storage\n```\n\nThese will enable internal DNS, the Kubernetes dashboard, and storage.\n\nStep 4: Check Cluster Status\nEnsure everything is set up correctly:\n\n```bash\nmicrok8s status --wait-ready\n```\n\n\n## Installing and Configuring K3s\nStep 1: Install the Master Node\nOn the main (master) node, run the following command to install K3s:\n\n```bash\ncurl -sfL https://get.k3s.io | sh -\n```\n\nThis will download and automatically configure K3s. A kubeconfig file will be generated and can be found at /etc/rancher/k3s/k3s.yaml.\n\nStep 2: Get the Token\nTo add worker nodes, you’ll need the token generated during installation. Retrieve it with:\n\n```bash\ncat /var/lib/rancher/k3s/server/node-token\n```\n\nStep 3: Add Worker Nodes\nOn each worker node, install K3s and connect it to the master:\n```bash\ncurl -sfL https://get.k3s.io | K3S_URL=https://<MASTER_IP>:6443 K3S_TOKEN=<TOKEN> sh -\n```\n\nStep 4: Verify the Cluster\nOn the master node, verify the connected nodes:\n\n```bash\nkubectl get nodes\n```\n\n## Testing the Cluster\nTo confirm that your cluster is working correctly, deploy a simple application:\n\n```bash\nkubectl create deployment nginx --image=nginx\nkubectl expose deployment nginx --type=NodePort --port=80\n```\n\nFind the exposed port using:\n\n```bash\nkubectl get services\n```\nAccess the application at http://<NODE_IP>:<PORT>.\n\n## Troubleshooting Common Issues in Kubernetes Clusters\n\nEven with a solid Kubernetes setup, issues are bound to arise. Here are some of the most common problems and how to address them effectively:\n\n1. DNS Issues in MicroK8s\nIf DNS isn’t working:\n  - Check if CoreDNS is running:\n```bash\nmicrok8s kubectl get pods -n kube-system\n```  \n\n  - If it's in CrashLoopBackOff, check the logs:\n```bash \nmicrok8s kubectl logs -n kube-system <coredns-pod-name>  \n```\n\n  - Ensure that iptables isn’t blocking DNS traffic:\n```bash\nsudo iptables -F  \n```\n\n2. Worker Nodes Not Connecting in K3s\nIf a worker node isn’t showing up in kubectl get nodes:\n\n   - Verify that you’re using the correct URL and token from the master node:\n```bash\ncat /var/lib/rancher/k3s/server/node-token  \n```\n\nOpen port 6443 on the master node:\n```bash\nsudo ufw allow 6443/tcp\n```\n3. Service Inaccessible\nIf your applications are unreachable:\n\n  - Check the NodePort for your service:\n```bash\nkubectl get services\n```\n  - Ensure readiness probes are properly configured:\n```bash\nkubectl describe pod <pod-name>  \n```\n\n  - Open the NodePort range (30000-32767):\n```bash\nsudo ufw allow 30000:32767/tcp  \n```\n\n4. Cluster Nodes in ‘NotReady’ State\nIf nodes are marked as NotReady:\n\n   - Check hardware resources:\n```bash\nfree -h\n```\n\n  - Make sure the container runtime (e.g., Docker/Containerd) is running:\n```bash\nsudo systemctl restart docker\n```\n\n   - Reinstall networking plugins:\n```bash\nmicrok8s enable dns flannel  \n```\n\n5. Pods Stuck in Pending State\nWhen pods can’t be scheduled:\n\n   - Inspect events for the pod:\n```bash\nkubectl describe pod <pod-name>  \n```\n\n   - Remove unnecessary taints from nodes:\n```bash\nkubectl taint nodes <node-name> key=value:NoSchedule-  \n```\n\nThese tips will help you quickly diagnose and resolve most Kubernetes cluster issues. The key is to dive into logs and system events to pinpoint where things are breaking down. Good luck! "},"previousPost":{"slug":"linux-file-system","frontMatter":{"title":"ZFS vs Btrfs vs EXT4: Which File System Should You Choose in 2025?","description":"When selecting a file system for your projects, it's essential to understand the pros and cons of each option based on the specific context in which you'll be using it. In 2025, ZFS, Btrfs, and EXT4 are three of the most popular choices, each with features that make them suitable for different environments, from desktops and servers to NAS (Network-Attached Storage). In this article, we'll break down each file system, comparing them in terms of characteristics, performance, and compatibility.","image":"/images/blog/ZFSvsBtrfsvsEXT4.jpg","date":"2024-12-29","category":"Server"},"content":"\n\n## EXT4 - Tried-and-True Stability and Simplicity\n\nEXT4 is undoubtedly the most widely used file system in Linux distributions and is often the go-to choice for users looking for stability and compatibility. Developed in 2008 as an improvement over EXT3, EXT4 offers excellent performance and resource efficiency.\n\nAdvantages:\n   - Stability and compatibility: EXT4 is incredibly stable and supported across almost all Linux distributions and management tools.\n   - Fast read/write performance: It performs very well with small to medium-sized files.\n   - Resilience to failure: With journaling, EXT4 ensures data integrity during sudden shutdowns.\n   - Moderate scalability: It can handle volumes up to 1 exabyte and file sizes up to 16 TB.\n\nDisadvantages:\n   - Lack of advanced features: EXT4 doesn't offer advanced features like deduplication, snapshots, or file compression that are available in other file systems.\n   - Not the best for handling very large files: It’s less efficient when working with massive files or complex data sets.\n\n<em>When to choose EXT4?</em>\n\n   - Desktops: If you need a stable and fast file system for a personal PC or laptop, EXT4 is a safe bet.\n   - Servers: For servers that don't require advanced functionality, EXT4 is often enough, but for large data sets or more data protection, other options may be better.\n   - NAS: If you’re using a NAS that doesn’t rely on complex backups and advanced data protection, EXT4 will serve you well.\n\n\n## ZFS - Advanced Data Protection and Performance\n\nOriginally developed by Sun Microsystems and now available on most Linux and BSD systems, ZFS is a file system known for its advanced features. It's frequently used in enterprise environments due to its ability to manage massive volumes of data and offer superior data protection.\n\nAdvantages:\n   - Data protection: ZFS includes mechanisms for checking and correcting errors at the file and disk levels.\n   - Snapshots and cloning: It supports fast snapshots and cloning, making backups and data restoration extremely quick.\n   - Deduplication and compression: ZFS allows for data deduplication to save space and file compression to reduce storage needs.\n   - Massive scalability: ZFS can handle file systems from a few gigabytes to hundreds of terabytes.\n   - Software RAID: It manages RAID directly at the file system level, providing additional protection compared to hardware RAID.\n\nDisadvantages:\n   - High resource usage: ZFS is known for its heavy memory and CPU requirements, making it less suitable for resource-limited systems.\n   - Limited compatibility: While available on Linux and BSD, ZFS isn’t natively supported on all distributions and is not available on Windows or macOS.\n   - Complex administration: Managing ZFS can be more challenging compared to EXT4, requiring more advanced knowledge.\n\n<em>When to choose ZFS?</em>\n\n   - Servers: ZFS is ideal for servers handling large volumes of data that require advanced data protection and fast backup capabilities.\n   - NAS: For NAS systems requiring reliability, quick backups, and data protection, ZFS is a top choice.\n   - Enterprise projects: Any infrastructure dealing with large files, snapshots, and fast recovery will benefit greatly from ZFS.\n\n\n\n## Btrfs - Flexibility and Advanced Features\n\nBtrfs is a younger file system compared to ZFS and EXT4, but it has rapidly gained popularity due to its advanced features, which are similar to ZFS. It was developed as a modern alternative to traditional file systems, optimized for managing large volumes and complex data.\n\nAdvantages:\n   - Snapshots and subvolumes: Btrfs allows for creating snapshots and subvolumes, making backups and data management more efficient.\n   - Compression and deduplication: Btrfs supports file compression and deduplication, saving a lot of storage space.\n   - Good performance with large files: It's faster than EXT4 when handling large files and large amounts of data.\n   - Linux integration: It’s natively supported by most Linux distributions, making it easy to implement on modern systems.\n\nDisadvantages:\n   - Instability in certain situations: While Btrfs is constantly improving, it has had some stability issues in the past, especially in production environments.\n   - Lower performance on older hardware: Using Btrfs on older systems or traditional hard drives may not be as fast or efficient.\n   - Not as robust as ZFS: While Btrfs offers many advanced features, it’s still not as mature or robust as ZFS for managing large-scale data.\n\n<em>When to choose Btrfs?</em>\n\n   - Desktops: Btrfs is a great choice for advanced users looking to experiment with features like deduplication, snapshots, and compression.\n   - Servers and NAS: For environments where managing large volumes of data and data protection are important, Btrfs is a viable option, though you should be mindful of its stability.\n   - Projects requiring a balance of performance and protection: If you need a modern file system with advanced features but don’t require the complexity of ZFS, Btrfs is a solid alternative.\n\n\n## Conclusion: Which File System Should You Choose in 2025?\nEach of these file systems has its own advantages and disadvantages, and the choice depends on your needs and resources.\n\n   - For desktops and users seeking simplicity and stability, EXT4 remains the go-to choice.\n   - For servers and NAS that need advanced data protection and large-scale data management, ZFS is the top pick.\n   - For users who want a balance of advanced features and performance without ZFS’s complexity, Btrfs is a modern and flexible choice.\n\nUltimately, based on your projects and available resources, you’ll be able to choose the file system that best meets your needs.\n"},"nextPost":{"slug":"Apache-on-Ubuntu-22.04-Using-Docker","frontMatter":{"title":"How to Install Apache on Ubuntu 22.04 Using Docker","description":"Apache is one of the most widely used web servers, providing a robust platform for hosting websites and web applications.","image":"/images/blog/docker.jpg","date":"2024-12-23","category":"Server"},"content":"\n\n\nApache is one of the most widely used web servers, providing a robust platform for hosting websites and web applications. With the power of Docker, you can easily run Apache in an isolated container, making your setup portable and quick to deploy. In this blog post, we will walk you through the steps to install and run Apache on Ubuntu 22.04 using Docker. This setup is perfect for testing, development, or production environments.\n\n## What You'll Learn.\n\n\nIn this guide, you'll learn:\n\n1.  How to install Docker on Ubuntu 22.04.\n2.  How to pull and run Apache in a Docker container.\n3.  Basic management of your Apache Docker container.\n4.  How to troubleshoot any potential issues during the setup.\n\n## Step 1 Install Docker on Ubuntu 22.04\n\nBefore we begin setting up Apache, we need to ensure that Docker is installed on your system. Docker allows us to run Apache within a container, providing a lightweight and efficient environment. Follow these steps to get Docker up and running:\n\n1.1 Update Your System\n\nStart by updating your package lists to make sure you’re working with the latest versions of the software.\n\n```bash\nsudo apt update\nsudo apt upgrade -y\n```\n\n1.2 Install Required Dependencies\n\nNext, we’ll install some necessary dependencies to allow Docker to be added to the system.\n\n```bash\nsudo apt install -y apt-transport-https ca-certificates curl software-properties-common\n```\n\n1.3 Add Docker’s Official GPG Key\n\nNow, you need to add Docker’s official GPG key to your system so it can verify the Docker package authenticity.\n\n\n**curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg**\n\n1.4 Add Docker’s Repository\n\nAdd Docker’s official repository to your system’s list of sources, so you can install the latest version of Docker from it.\n\n\n**echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null**\n\n\n1.5 Install Docker\n\nNow you can install Docker. After updating your package list, install Docker using the following command:\n\n```bash\nsudo apt update\nsudo apt install -y docker-ce docker-ce-cli containerd.io\n```\n\n1.6 Verify Docker Installation\n\nTo confirm Docker was installed successfully, check the version of Docker installed:\n\n```bash\nsudo docker --version\n```\n## Step 2 Run Apache in a Docker Container\n\nNow that Docker is installed, it's time to pull the official Apache image and run it in a container. Docker makes it incredibly easy to run a fully functional Apache web server without the need to configure anything manually.\n\n2.1 Pull the Official Apache Image\n\nDocker Hub has a ready-to-use official Apache image, so you don't have to create one from scratch. Pull the image by running:\n\n```bash\nsudo docker pull httpd\n```\n2.2 Run Apache in a Docker Container\n\nWith the Apache image pulled, we can now run it in a container. This will start Apache and bind it to your machine's port 8080:\n\n```bash\nsudo docker run -d -p 8080:80 --name apache-server httpd\n```\n-d: Runs the container in detached mode (in the background).\n-p 8080:80: Maps port 80 inside the container (the default Apache port) to port 8080 on your host machine.\n--name apache-server: Names your container \"apache-server\" for easy reference.\n\n2.3 Verify the Apache Container is Running\n\nTo check if your container is running properly, you can use:\n```bash\nsudo docker ps\n```\nThis command will list all running containers, and you should see your apache-server container in the list.\n\n2.4 Access Apache in Your Browser\n\nNow, open your browser and navigate to http://localhost:8080 or http://<your-server-ip>:8080 (if you're working on a remote machine). You should see the default Apache welcome page, which indicates that Apache is running inside the Docker container.\n\n## Step 3 Managing Your Apache Docker Container\n\nOnce your Apache server is running, you may need to perform some basic container management tasks. Here are some useful commands:\n\n3.1 Stop the Apache Container\n\nIf you need to stop the Apache container, you can use the following command:\n\n```bash\nsudo docker stop apache-server\n```\n3.2 Start the Apache Container Again\n\nTo start the container again after stopping it:\n\n```bash\nsudo docker start apache-server\n```\n\n3.3 Remove the Apache Container\n\nIf you want to remove the container (for example, when cleaning up), use this command:\n\n```bash\nsudo docker rm apache-server\n```\n3.4 View Apache Logs\n\nTo view the logs generated by Apache inside the container:\n\n```bash\nsudo docker logs apache-server\n```\n\n## Step 4 Customize Your Apache Setup\n\nAt this point, you have Apache running in Docker with its default configuration. However, Docker allows for greater flexibility, enabling you to configure Apache further. You can mount configuration files or a custom website directory into your container, or even create a custom Dockerfile to suit your specific needs.\n\n4.1 Mounting Local Directories to Docker\n\nIf you want to serve your custom website, you can mount your local directory to the Apache container:\n```bash\nsudo docker run -d -p 8080:80 -v /path/to/your/website:/usr/local/apache2/htdocs/ --name apache-server httpd\n```\nThis command mounts the website directory on your host machine to the htdocs folder in the Apache container, where Apache looks for files to serve.\n\n## Troubleshooting Common Issues\n\nDocker Image Pull Failures: Ensure you have a stable internet connection. If you encounter issues while pulling the Apache image, try running docker system prune to clear unused data and try again.\nPort Conflicts: If port 8080 is already in use, you can change the host port (e.g., -p 8081:80) when running the container.\nApache Errors: To check for any issues with Apache itself, use docker logs apache-server to view the container's log output.\n\n## Conclusion\nCongratulations! You’ve successfully set up Apache on Ubuntu 22.04 using Docker. This method is a clean and efficient way to run a web server, with the added benefits of Docker’s portability and ease of use. You can now scale your Apache setup, customize it, or even deploy it in production with minimal effort. Docker makes managing your server environments a breeze, and using Apache in a containerized environment is a powerful choice for modern web hosting.\n\nIf you want to take it a step further, you can integrate Docker Compose to manage multi-container applications or even link Apache with a MySQL or PHP container for dynamic website hosting.\n\nHappy coding, and enjoy your new Apache web server!"}},"__N_SSG":true}